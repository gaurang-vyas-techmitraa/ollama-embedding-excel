# ollama-embedding-excel

# install ollama in local
# load excel file like

<img width="908" height="270" alt="image" src="https://github.com/user-attachments/assets/998f1903-9d4c-478d-bd71-1a2cd30d1fee" />

# streamlit run read_excel.py  - execute command in terminal
Perfect for building document Q&amp;A systems, contract analyzers, or personal research tools — all powered by local models.
🧠 Built a Local RAG Chatbot with Ollama Embeddings!
Excited to share a mini project I just built — a private, local-first chatbot that lets you upload a PDF, ask questions about it, and get smart answers — all without sending your data to the cloud! 🛡️

🧰 Stack & Tools:

🔹 Streamlit – for the simple and clean UI

🔹 Ollama – for running powerful open-source LLMs locally (like Mistral, Llama3, etc.)

🔹 PyPDFLoader – to load and process your PDFs

🔹 FAISS – fast and lightweight vector database for semantic search

🔹 langchain – to handle document loading, text splitting, embeddings, and RetrievalQA

🚀 Features:

Upload any PDF 📄

Automatically chunk and embed text with nomic-embed-text

Ask questions in natural language

Get context-aware answers pulled directly from your document!

💡 Perfect for building document Q&A systems, contract analyzers, or personal research tools — all powered by local models.

<img width="1570" height="961" alt="image" src="https://github.com/user-attachments/assets/26d768ca-1bb1-4c05-ae34-20f22327ba19" />

